#!/usr/bin/env python3
"""
éŸ³å£°å‡¦ç†æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€ãƒ¬ãƒ™ãƒ«è¨ˆç®—ã€éŒ²éŸ³æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™
"""

import asyncio
import base64
import numpy as np
import wave
import io
from datetime import datetime
from typing import List

from app.services.audio_processing_service import AudioProcessingService, AudioChunk
from app.schemas.websocket import AudioDataMessage


def generate_test_audio(
    duration_ms: int = 100, frequency: float = 440.0, amplitude: float = 0.5
) -> bytes:
    """ãƒ†ã‚¹ãƒˆç”¨éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    sample_rate = 16000
    samples = int(sample_rate * duration_ms / 1000)

    # ã‚µã‚¤ãƒ³æ³¢ã‚’ç”Ÿæˆ
    t = np.linspace(0, duration_ms / 1000, samples, False)
    audio_data = amplitude * np.sin(2 * np.pi * frequency * t)

    # 16-bitæ•´æ•°ã«å¤‰æ›
    audio_int16 = (audio_data * 32767).astype(np.int16)

    return audio_int16.tobytes()


def generate_silence(duration_ms: int = 100) -> bytes:
    """ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    sample_rate = 16000
    samples = int(sample_rate * duration_ms / 1000)

    # ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿
    audio_data = np.zeros(samples, dtype=np.int16)

    return audio_data.tobytes()


async def test_audio_processing():
    """éŸ³å£°å‡¦ç†æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸµ éŸ³å£°å‡¦ç†æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 50)

    # éŸ³å£°å‡¦ç†ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
    audio_processor = AudioProcessingService()

    # ãƒ†ã‚¹ãƒˆç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
    session_id = "test-audio-session"
    user_id = 1

    try:
        # 1. éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("ğŸ“Š 1. éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ")

        # 440Hzã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        audio_data_440 = generate_test_audio(100, 440.0, 0.5)
        print(f"   âœ… 440HzéŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {len(audio_data_440)} bytes")

        # ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿
        silence_data = generate_silence(100)
        print(f"   âœ… ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ: {len(silence_data)} bytes")

        # 2. éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š 2. éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ")

        # 440HzéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        audio_message_440 = AudioDataMessage(
            session_id=session_id,
            user_id=user_id,
            data=base64.b64encode(audio_data_440).decode(),
            timestamp=datetime.now().isoformat(),
            chunk_id="test_chunk_440",
            sample_rate=16000,
            channels=1,
        )

        chunk_440 = await audio_processor.process_audio_data(audio_message_440)
        print(f"   âœ… 440HzéŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {chunk_440.chunk_id}")

        # ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        audio_message_silence = AudioDataMessage(
            session_id=session_id,
            user_id=user_id,
            data=base64.b64encode(silence_data).decode(),
            timestamp=datetime.now().isoformat(),
            chunk_id="test_chunk_silence",
            sample_rate=16000,
            channels=1,
        )

        chunk_silence = await audio_processor.process_audio_data(audio_message_silence)
        print(f"   âœ… ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {chunk_silence.chunk_id}")

        # 3. éŸ³å£°ãƒ¬ãƒ™ãƒ«è¨ˆç®—ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š 3. éŸ³å£°ãƒ¬ãƒ™ãƒ«è¨ˆç®—ãƒ†ã‚¹ãƒˆ")

        # 440HzéŸ³å£°ã®ãƒ¬ãƒ™ãƒ«è¨ˆç®—
        level_440 = audio_processor._calculate_audio_level(chunk_440)
        print(f"   ğŸ“ˆ 440HzéŸ³å£°ãƒ¬ãƒ™ãƒ«: {level_440.level:.4f}")
        print(f"   ğŸ¤ è©±è€…æ¤œå‡º: {level_440.is_speaking}")
        print(f"   ğŸ“Š RMS: {level_440.rms:.4f}")
        print(f"   ğŸ“Š ãƒ”ãƒ¼ã‚¯: {level_440.peak:.4f}")

        # ç„¡éŸ³ã®ãƒ¬ãƒ™ãƒ«è¨ˆç®—
        level_silence = audio_processor._calculate_audio_level(chunk_silence)
        print(f"   ğŸ“ˆ ç„¡éŸ³ãƒ¬ãƒ™ãƒ«: {level_silence.level:.4f}")
        print(f"   ğŸ¤ è©±è€…æ¤œå‡º: {level_silence.is_speaking}")
        print(f"   ğŸ“Š RMS: {level_silence.rms:.4f}")
        print(f"   ğŸ“Š ãƒ”ãƒ¼ã‚¯: {level_silence.peak:.4f}")

        # 4. éŒ²éŸ³æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š 4. éŒ²éŸ³æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")

        # éŒ²éŸ³é–‹å§‹
        await audio_processor.start_recording(session_id)
        print("   âœ… éŒ²éŸ³é–‹å§‹")

        # éŒ²éŸ³ä¸­ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        for i in range(5):
            audio_data = generate_test_audio(100, 440.0 + i * 100, 0.3)
            audio_message = AudioDataMessage(
                session_id=session_id,
                user_id=user_id,
                data=base64.b64encode(audio_data).decode(),
                timestamp=datetime.now().isoformat(),
                chunk_id=f"recording_chunk_{i}",
                sample_rate=16000,
                channels=1,
            )

            chunk = await audio_processor.process_audio_data(audio_message)
            print(f"   ğŸ“ éŒ²éŸ³ãƒãƒ£ãƒ³ã‚¯ {i + 1}: {chunk.chunk_id}")

        # éŒ²éŸ³åœæ­¢
        await audio_processor.stop_recording(session_id)
        print("   âœ… éŒ²éŸ³åœæ­¢")

        # 5. éŸ³å£°ãƒ¬ãƒ™ãƒ«å±¥æ­´ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š 5. éŸ³å£°ãƒ¬ãƒ™ãƒ«å±¥æ­´ãƒ†ã‚¹ãƒˆ")

        levels = await audio_processor.get_session_audio_levels(session_id, user_id)
        print(f"   ğŸ“ˆ éŸ³å£°ãƒ¬ãƒ™ãƒ«å±¥æ­´: {len(levels)} ä»¶")

        for i, level in enumerate(levels):
            print(
                f"      {i + 1}. ãƒ¬ãƒ™ãƒ«: {level.level:.4f}, è©±è€…: {level.is_speaking}"
            )

        # 6. å‚åŠ è€…éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š 6. å‚åŠ è€…éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒ†ã‚¹ãƒˆ")

        participant_levels = (
            await audio_processor.get_session_participants_audio_levels(session_id)
        )
        print(f"   ğŸ‘¥ å‚åŠ è€…æ•°: {len(participant_levels)}")

        for user_id, level in participant_levels.items():
            print(
                f"      ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_id}: ãƒ¬ãƒ™ãƒ« {level.level:.4f}, è©±è€… {level.is_speaking}"
            )

        # 7. éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š 7. éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ãƒ†ã‚¹ãƒˆ")

        # RAW â†’ WAVå¤‰æ›
        raw_data = generate_test_audio(100, 440.0, 0.5)
        wav_data = audio_processor.convert_audio_format(raw_data, "raw", "wav", 16000)
        print(f"   âœ… RAW â†’ WAVå¤‰æ›: {len(raw_data)} â†’ {len(wav_data)} bytes")

        # WAV â†’ RAWå¤‰æ›
        raw_data_converted = audio_processor.convert_audio_format(
            wav_data, "wav", "raw"
        )
        print(f"   âœ… WAV â†’ RAWå¤‰æ›: {len(wav_data)} â†’ {len(raw_data_converted)} bytes")

        # 8. ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢ãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š 8. ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢ãƒ†ã‚¹ãƒˆ")

        await audio_processor.clear_session_buffer(session_id)
        print("   âœ… éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

        # ã‚¯ãƒªã‚¢å¾Œã®çŠ¶æ…‹ç¢ºèª
        levels_after_clear = await audio_processor.get_session_audio_levels(
            session_id, user_id
        )
        print(f"   ğŸ“Š ã‚¯ãƒªã‚¢å¾Œã®ãƒ¬ãƒ™ãƒ«æ•°: {len(levels_after_clear)}")

        print("\nâœ… éŸ³å£°å‡¦ç†æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Œäº†")

    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        raise


async def test_multiple_users():
    """è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ‘¥ è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼éŸ³å£°å‡¦ç†ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)

    audio_processor = AudioProcessingService()
    session_id = "test-multi-user-session"

    try:
        # 3äººã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒéŸ³å£°ã‚’é€ä¿¡
        for user_id in range(1, 4):
            # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç•°ãªã‚‹å‘¨æ³¢æ•°ã®éŸ³å£°ã‚’é€ä¿¡
            frequency = 440.0 + (user_id - 1) * 100
            audio_data = generate_test_audio(100, frequency, 0.3)

            audio_message = AudioDataMessage(
                session_id=session_id,
                user_id=user_id,
                data=base64.b64encode(audio_data).decode(),
                timestamp=datetime.now().isoformat(),
                chunk_id=f"multi_user_chunk_{user_id}",
                sample_rate=16000,
                channels=1,
            )

            chunk = await audio_processor.process_audio_data(audio_message)
            level = audio_processor._calculate_audio_level(chunk)

            print(
                f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_id}: å‘¨æ³¢æ•° {frequency}Hz, ãƒ¬ãƒ™ãƒ« {level.level:.4f}"
            )

        # å…¨å‚åŠ è€…ã®éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’å–å¾—
        participant_levels = (
            await audio_processor.get_session_participants_audio_levels(session_id)
        )
        print(f"\nğŸ“Š å‚åŠ è€…éŸ³å£°ãƒ¬ãƒ™ãƒ«:")

        for user_id, level in participant_levels.items():
            print(
                f"   ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼ {user_id}: ãƒ¬ãƒ™ãƒ« {level.level:.4f}, è©±è€… {level.is_speaking}"
            )

        print("âœ… è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†")

    except Exception as e:
        print(f"âŒ è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    print("ğŸš€ éŸ³å£°å‡¦ç†ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¾ã™")

    # å˜ä¸€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ã‚¹ãƒˆ
    asyncio.run(test_audio_processing())

    # è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ†ã‚¹ãƒˆ
    asyncio.run(test_multiple_users())

    print("\nğŸ‰ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ")
